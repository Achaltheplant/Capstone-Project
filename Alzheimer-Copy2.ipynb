{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240aac88-26ed-43a0-937d-cc2ca5995bec",
   "metadata": {},
   "source": [
    "# PHASE 4: MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93b7dc-1b65-476c-b053-c7787acd6a95",
   "metadata": {},
   "source": [
    "## MODEL#1 RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b41ff8-c44d-42db-9838-079b4bfb5ccd",
   "metadata": {},
   "source": [
    "#### This model was chosen due to its stability and because it handles non linear data well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "702c94d1-ce05-498c-816a-d4687ba6b910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9441860465116279\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       278\n",
      "           1       0.94      0.89      0.92       152\n",
      "\n",
      "    accuracy                           0.94       430\n",
      "   macro avg       0.94      0.93      0.94       430\n",
      "weighted avg       0.94      0.94      0.94       430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[270   8]\n",
      " [ 16 136]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "data = pd.read_csv(\"alzheimers_disease_data.csv\")\n",
    "data.drop(['PatientID', 'DoctorInCharge'], axis=1, inplace=True)\n",
    "# -----------------------------\n",
    "# 2. Separate features + target\n",
    "# -----------------------------\n",
    "X = data.drop(\"Diagnosis\", axis=1)   # all features\n",
    "y = data[\"Diagnosis\"]                # target\n",
    "\n",
    "# If Diagnosis is categorical, convert to numeric\n",
    "if y.dtype == 'object':\n",
    "    y = y.astype('category').cat.codes\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Train/test split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Build Random Forest model\n",
    "# -----------------------------\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Predictions\n",
    "# -----------------------------\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Evaluation\n",
    "# -----------------------------\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4555b31c-493b-4642-84bf-6174d89f8d10",
   "metadata": {},
   "source": [
    "## MODEL#2 XG BOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af88828-a434-462d-9b71-f4878fbf8455",
   "metadata": {},
   "source": [
    "#### This model was chosen because it is what is commonly used in smaller medical datasets since it handles mixed numerical and categorical data well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53d46edd-6d2c-4645-a361-075b2f64c7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9534883720930233\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       277\n",
      "           1       0.96      0.91      0.93       153\n",
      "\n",
      "    accuracy                           0.95       430\n",
      "   macro avg       0.95      0.94      0.95       430\n",
      "weighted avg       0.95      0.95      0.95       430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[271   6]\n",
      " [ 14 139]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. Prepare data (using 'data', not df)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# Identify target column\n",
    "target_col = \"Diagnosis\"   # change if your target has a different name\n",
    "\n",
    "# Encode target labels if they are non-numeric\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data[target_col])\n",
    "\n",
    "# Features = everything except the target\n",
    "X = data.drop(columns=[target_col])\n",
    "\n",
    "# If categorical features exist, convert them to numeric using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. Train-test split\n",
    "# -----------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. XGBoost Model\n",
    "# -----------------------------------------------------\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. Predictions\n",
    "# -----------------------------------------------------\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. Evaluation\n",
    "# -----------------------------------------------------\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72fc4c9-6c6c-4514-9266-5f5d0e47a695",
   "metadata": {},
   "source": [
    "## MODEL#3 LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4fc869-f5e0-4134-9873-cf2c6ad3816a",
   "metadata": {},
   "source": [
    "#### This model was chosen for its simpleness and interpretability and is also used in medical datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44a0d2a4-0304-49c1-9178-1709924ddd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8302325581395349\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       277\n",
      "           1       0.78      0.73      0.75       153\n",
      "\n",
      "    accuracy                           0.83       430\n",
      "   macro avg       0.82      0.81      0.81       430\n",
      "weighted avg       0.83      0.83      0.83       430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[246  31]\n",
      " [ 42 111]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achal\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. Prepare data (using 'data')\n",
    "# -----------------------------------------------------\n",
    "\n",
    "target_col = \"Diagnosis\"   # change if your target has another name\n",
    "\n",
    "# Encode target if it is categorical\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data[target_col])\n",
    "\n",
    "# Features = everything except the target\n",
    "X = data.drop(columns=[target_col])\n",
    "\n",
    "# Convert categorical predictors to numeric (one-hot encoding)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. Train-test split\n",
    "# -----------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. Logistic Regression Model\n",
    "# -----------------------------------------------------\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=500,\n",
    "    solver='lbfgs'\n",
    ")\n",
    "\n",
    "# Train model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. Predictions\n",
    "# -----------------------------------------------------\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. Evaluation\n",
    "# -----------------------------------------------------\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0578cb3-080e-41ca-a798-60bc37e353bb",
   "metadata": {},
   "source": [
    "## MODEL#4 SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02302952-760e-493b-a58b-6cdb0c4aa913",
   "metadata": {},
   "source": [
    "#### This model was chosen because its good for small datasets and effective with scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97062496-b7e0-46f6-a2c5-1a094d6a7843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8325581395348837\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       277\n",
      "           1       0.80      0.71      0.75       153\n",
      "\n",
      "    accuracy                           0.83       430\n",
      "   macro avg       0.82      0.80      0.81       430\n",
      "weighted avg       0.83      0.83      0.83       430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[250  27]\n",
      " [ 45 108]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. Prepare the data\n",
    "# -----------------------------------------------------\n",
    "\n",
    "target_col = \"Diagnosis\"   # Change if your target has another name\n",
    "\n",
    "# Encode target labels if non-numeric\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data[target_col])\n",
    "\n",
    "# Features (except target)\n",
    "X = data.drop(columns=[target_col])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. Train-test split\n",
    "# -----------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. Scaling (VERY important for SVM)\n",
    "# -----------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. SVM Model (RBF kernel)\n",
    "# -----------------------------------------------------\n",
    "svm_clf = SVC(\n",
    "    kernel='rbf',\n",
    "    C=1.0,\n",
    "    gamma='scale',\n",
    "    probability=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. Predictions\n",
    "# -----------------------------------------------------\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6. Evaluation\n",
    "# -----------------------------------------------------\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdfb7d-92ba-40e3-9a7a-01212abd2783",
   "metadata": {},
   "source": [
    "#### From the above 4 models' comparison, it can be seen that model 2, XG BOOST offers the best predictive capabilities with an accuracy of 95% predicting 271 true negatives 6 false positives which is a false alarm but medically less dangerous than getting a false negative, 14 false negatives and 139 true posistives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22de0527-f9d6-440c-b5f8-fd2becf22e6b",
   "metadata": {},
   "source": [
    "# PHASE 5: EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73933423-fca8-4134-b9c3-1afbc48d1307",
   "metadata": {},
   "source": [
    "####  MODEL             ACCURACY     RECALL(0)     RECALL(1)     CONFUSION MATRIX\n",
    "#### RANDOM FOREST        94.42%        0.97          0.89          [270,  8]\n",
    "####      >                                                         [16 ,136]\n",
    "#### XG BOOST             95.35%        0.98          0.91          [271,  6]\n",
    "####                                                                [14 ,139]\n",
    "#### LOGISTIC REGRESSION  83.02%        0.89          0.73          [246, 31]\n",
    "####                                                                [42 ,111]\n",
    "#### SVM                  83.26%        0.90          0.71          [250, 27]\n",
    "####                                                                [45 ,108]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a1993-bc01-4a7b-a372-98eaa41dfe52",
   "metadata": {},
   "source": [
    "# PHASE 6: DEPLOYMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f399b-44d2-4f19-8047-d63b9c00ba74",
   "metadata": {},
   "source": [
    "## XG BOOST MODEL FOR TRAINING AND TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d06eee-7d83-4b98-9edf-b04262bead5e",
   "metadata": {},
   "source": [
    "#### This train-test split used 80% train since that is standard and usually enough for a model to learn patterns and 20% test since that is a sufficient unknown portion which can be utilised to test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a658708-0094-4b85-b235-27fbb222425d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# SELECT FEATURES\n",
    "FEATURE_COLUMNS = [\n",
    "    \"MMSE\",\n",
    "    \"FunctionalAssessment\",\n",
    "    \"MemoryComplaints\",\n",
    "    \"BehavioralProblems\",\n",
    "    \"ADL\"\n",
    "]\n",
    "\n",
    "TARGET_COL = \"Diagnosis\"\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data[TARGET_COL])\n",
    "\n",
    "\n",
    "X = data[FEATURE_COLUMNS].copy()\n",
    "\n",
    "for col in X.columns:\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(model, \"alz_model.joblib\")\n",
    "joblib.dump(le, \"alz_label_encoder.joblib\")\n",
    "joblib.dump(FEATURE_COLUMNS, \"alz_features.joblib\")\n",
    "\n",
    "print(\"Model trained and saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c486f3-a618-4d50-a377-d555937137f8",
   "metadata": {},
   "source": [
    "## ALZEIMERS' PREDICTION TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06e51ac8-6cf4-4292-a4cb-10cc7009dd4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== INPUT SCALE ==========\n",
      "MMSE (Mini-Mental State Examination): 0–30\n",
      "Functional Assessment: 0–5 \n",
      "Memory Complaints: 0 = No, 1 = Yes\n",
      "Behavioral Problems: 0 = No, 1 = Yes\n",
      "ADL (Activities of Daily Living): 0–6 \n",
      "=================================\n",
      "\n",
      "Enter the following values:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "MMSE score:  23\n",
      "Functional Assessment score:  4\n",
      "Memory Complaints (0 = No, 1 = Yes):  1\n",
      "Behavioral Problems (0 = No, 1 = Yes):  1\n",
      "ADL score:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------\n",
      "Prediction: Alzheimer's\n",
      "Confidence: 1.00\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "def predict_alzheimers_interactive():\n",
    "\n",
    "    model = joblib.load(\"alz_model.joblib\")\n",
    "    le = joblib.load(\"alz_label_encoder.joblib\")\n",
    "    features = joblib.load(\"alz_features.joblib\")\n",
    "\n",
    "    print(\"\\n========== INPUT SCALE ==========\")\n",
    "    print(\"MMSE (Mini-Mental State Examination): 0–30\")\n",
    "    print(\"Functional Assessment: 0–5 \")\n",
    "    print(\"Memory Complaints: 0 = No, 1 = Yes\")\n",
    "    print(\"Behavioral Problems: 0 = No, 1 = Yes\")\n",
    "    print(\"ADL (Activities of Daily Living): 0–6 \")\n",
    "    print(\"=================================\\n\")\n",
    "\n",
    "    print(\"Enter the following values:\")\n",
    "    mmse = float(input(\"MMSE score: \"))\n",
    "    functional_assessment = float(input(\"Functional Assessment score: \"))\n",
    "    memory_complaints = float(input(\"Memory Complaints (0 = No, 1 = Yes): \"))\n",
    "    behavioral_problems = float(input(\"Behavioral Problems (0 = No, 1 = Yes): \"))\n",
    "    adl = float(input(\"ADL score: \"))\n",
    "\n",
    "    row = pd.DataFrame([[\n",
    "        mmse,\n",
    "        functional_assessment,\n",
    "        memory_complaints,\n",
    "        behavioral_problems,\n",
    "        adl\n",
    "    ]], columns=features)\n",
    "\n",
    "    pred_num = int(model.predict(row)[0])\n",
    "\n",
    "    label_map = {\n",
    "        0: \"Not Alzheimer's\",\n",
    "        1: \"Alzheimer's\"\n",
    "    }\n",
    "    pred_label = label_map.get(pred_num, \"Unknown\")\n",
    "\n",
    "    prob = model.predict_proba(row)[0].max()\n",
    "\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    print(\"Prediction:\", pred_label)\n",
    "    print(f\"Confidence: {prob:.2f}\")\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "predict_alzheimers_interactive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca0748-f9a9-46ef-ba98-00131332e60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
